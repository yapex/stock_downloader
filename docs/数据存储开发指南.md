# 数据存储开发指南

本文档为开发者提供访问和使用 `stock_downloader` 项目所存储数据的详细指南。

## 1. 技术核心

本项目的数据存储采用现代化的本地数据湖架构，其核心技术如下：

- **查询引擎 (Query Engine)**: **DuckDB**
  - 一个高性能的嵌入式分析数据库，无需启动任何数据库服务（Serverless）。
  - 通过标准 SQL 即可查询。

- **存储格式 (Storage Format)**: **Apache Parquet**
  - 高效的列式存储格式，提供高压缩比和快速的分析查询性能。
  - 所有数据文件存储在项目根目录的 `data/parquet/` 文件夹下。

- **查询入口 (Query Entry Point)**: `data/metadata.db`
  - 这是**唯一**的查询入口文件。它是一个 DuckDB 数据库，本身不存储任何庞大的业务数据，仅包含所有数据表的**模式 (Schema)**和指向 Parquet 数据文件的**元数据索引**。
  - 任何兼容 DuckDB 的客户端或库都可以通过连接此文件来查询整个数据湖。

- **数据分区 (Data Partitioning)**
  - 所有按日期记录的数据表都额外增加了一个 `year` 列作为**分区键**。在查询时利用此字段作为过滤条件，可以极大提升查询性能。

## 2. 快速上手

您可以通过任何支持 DuckDB 的工具连接 `data/metadata.db` 文件进行查询。以下是一个 Python 示例。

### 2.1. 环境准备

首先，请确保您已安装 `duckdb` 和 `pandas` 库。

```bash
pip install duckdb pandas
```

### 2.2. Python 查询示例

下面的代码演示了如何连接数据库，并查询“每日基本面指标” (`daily_basic`) 表的少量数据。

```python
import duckdb
import pandas

# 定义元数据数据库的路径
DB_FILE = "data/metadata.db"

# 使用 with 语句确保连接自动关闭
try:
    with duckdb.connect(database=DB_FILE, read_only=True) as con:
        print("Successfully connected to DuckDB.")

        # 示例1：查看所有可用的表
        print("\n--- Available Tables ---")
        tables = con.execute("SHOW TABLES;").fetchdf()
        print(tables)

        # 示例2：查询 'daily_basic' 表的前 5 条数据
        print("\n--- Querying daily_basic (first 5 rows) ---")
        daily_basic_df = con.execute("SELECT * FROM daily_basic LIMIT 5;").fetchdf()
        print(daily_basic_df)

        # 示例3：利用分区键 'year' 高效查询贵州茅台2023年后的利润表数据
        print("\n--- Querying income_statement for 600519.SH (year >= 2023) ---")
        income_statement_df = con.execute(
            """
            SELECT end_date, n_income, total_revenue
            FROM income_statement
            WHERE
                ts_code = '600519.SH'
                AND year >= 2023
            ORDER BY end_date DESC;
            """
        ).fetchdf()
        print(income_statement_df)

except duckdb.Error as e:
    print(f"An error occurred: {e}")

```

## 3. 数据查询最佳实践

### 3.1. 必须利用 `year` 分区键提升性能

数据湖中的核心设计之一就是按 `year` 字段对时间序列数据进行了**分区（Partitioning）**。这个字段并非由原始数据源（如Tushare）提供，而是项目在数据处理阶段为了优化性能特意添加的。

在查询时，**必须在 `WHERE` 子句中加入对 `year` 的过滤条件**，例如 `WHERE year = 2023`。这样做可以触发 DuckDB 的分区裁剪（Partition Pruning）功能，使其仅扫描对应年份的 Parquet 文件，从而将查询性能提升数个数量级。

这远比使用 `LIKE` 对日期字符串（如 `end_date LIKE '2023%'`）进行过滤要高效得多。

### 3.2. 精确查询年度报告的最佳实践

当需要查询特定年份的**年度报告**时，最高效且最准确的方式是**组合使用 `year` 和 `end_date` 字段**：

```sql
-- 查询 600519.SH 的2022年年度现金流量表
SELECT * FROM cash_flow
WHERE
  ts_code = '600519.SH'
  AND year = 2022 -- 1. 利用分区键快速定位到2022年数据
  AND end_date LIKE '%1231'; -- 2. 在分区内部精确匹配年度报告
```
这种方式兼具了分区查询的性能和业务逻辑的准确性。

### 3.3. 使用内置查询脚本

本项目在 `scripts/` 目录下提供了一个命令行查询工具 `query_parquet_data.py`，方便快速执行 SQL 查询。

**查询示例：**

查询贵州茅台（600519.SH）自2015年以来的净利润：

```bash
uv run python scripts/query_parquet_data.py --sql "SELECT end_date, n_income FROM income_statement WHERE ts_code = '600519.SH' AND year >= '2015' ORDER BY end_date DESC"
```

## 4. 可用数据表及结构

以下是当前数据湖中所有可用的数据表。完整的表结构（包括所有字段名、类型、主键等）定义在项目根目录的 `stock_schema.toml` 文件中，请直接参考该文件以获取最准确的 schema 信息。

> [!IMPORTANT]
> 除 `stock_basic` 表外，所有其他记录时间序列数据的表都包含一个由系统自动添加的 `year` 字段作为分区键，用于提升查询性能。`stock_basic` 为静态维度表，因此不包含 `year` 字段。

---

- **`stock_basic`**: 股票基本信息表字段
- **`stock_daily`**: 股票日线数据字段
- **`stock_adj_qfq`**: 复权行情数据字段
- **`daily_basic`**: 获取全部股票每日重要的基本面指标
- **`income_statement`**: 利润表字段
- **`balance_sheet`**: 资产负债表字段
- **`cash_flow`**: 现金流量表字段
- **`trade_cal`**: 交易日历
