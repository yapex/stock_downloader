### 最终架构方案：基于本地化部署的弹性股票分析引擎

这个架构方案专为在单台服务器上进行高效、可靠部署而设计，核心优势在于其**简单性**、**零依赖**和**强大的并发处理能力**。

---

### 核心设计原则

1.  **计算与存储分离 (逻辑上)**：虽然所有数据都在本地磁盘，但我们依然遵循计算存储分离的最佳实践。**元数据**（数据的“目录”）和**实际数据**（海量 Parquet 文件）分开存放。这种方式让系统结构清晰，未来即便要迁移到云端也更容易。
2.  **写操作与读操作的物理隔离**：数据更新由一个独立的**后台进程**（Huey Consumer）负责，而数据查询由另一个**前台进程**（Web 应用）负责。它们通过一个中央协调点——DuckDB 数据库文件——进行交互，但彼此不会直接干扰。
3.  **事务是原子性的黄金标准**：所有的数据变更操作，无论多么复杂，都被封装在一个 ACID 事务中。这保证了数据的完整性和一致性，杜绝了“部分更新”或“脏数据”的可能。

---

### 架构三大核心组件

#### 1. 任务总线 (The Conductor) - Huey

- **角色定位**: 整个系统的“指挥家”或“调度员”。它不处理数据，只负责在正确的时间，唤醒正确的工作进程来执行任务。
- **工作原理**:
  - **守护进程**: 您会在服务器上启动一个 Huey 的 `consumer` 进程。这个进程会像一个忠诚的管家一样，在后台持续运行，时刻监听任务队列。
  - **调度机制**: 您预先定义了一个“每日数据更新”任务，并为其设定了一个时间表（例如，每天凌晨 3 点）。时间一到，Huey 就会将这个任务指令放入队列。
  - **任务执行**: `consumer` 进程从队列中取出任务指令，并执行与之关联的 Python 函数。这个函数包含了从数据拉取到最终加载进数据库的全部逻辑。
- **为什么是它**: Huey 非常轻量级，可以用一个简单的 SQLite 文件作为任务队列的后端，无需像 RabbitMQ 或 Redis 那样部署额外的服务。这完美契合了我们“简单、自包含”的设计目标。

#### 2. 数据核心 (The Brain & The Library) - DuckDB & DuckLake

这是整个架构的“心脏”和“大脑”，由两部分协同工作：

- **a) 元数据中心 (The Brain): DuckDB 数据库文件 (`.db` file)**

  - **角色定位**: 它是系统的**唯一信任源 (Single Source of Truth)** 和**中央协调点**。
  - **存储内容**: 这个文件**不存储**海量的股票数据。它只存储“元数据”——关于数据的描述信息，就像图书馆的中央索引卡系统。具体包括：
    1.  **表结构定义 (Schema)**: `stocks` 表有哪些列（日期、代码、价格等），各是什么数据类型。
    2.  **文件清单 (File Manifest)**: `stocks` 表的数据具体存储在哪些 Parquet 文件的哪个路径下。
    3.  **事务日志 (Transaction Log)**: 用于实现 ACID 特性和 MVCC 的内部记录。
  - **工作原理**: 任何对 `stocks` 表的操作，无论是写入还是读取，都必须首先通过连接这个 `.db` 文件来进行。它充当了所有进程访问数据的“唯一入口”。

- **b) 数据仓库 (The Library): 本地 Parquet 文件目录**
  - **角色定位**: 这是存放所有实际股票数据的“图书馆”。
  - **存储内容**: 按日期分区的海量 Parquet 文件。Parquet 是一种列式存储格式，极度优化了分析查询的性能。当您查询特定股票某时间段的收盘价时，DuckDB 无需读取整个文件的所有数据，只需精准地读取“股票代码”和“收盘价”这两列，以及对应日期分区的文件，极大地提升了 I/O 效率。
  - **管理方式**: 这个目录由 **DuckLake** 扩展自动管理。当您通过元数据文件执行 `COPY` 或 `INSERT` 命令时，DuckLake 负责将数据以正确的格式和分区结构写入这个目录。

#### 3. 查询服务 (The Public Interface) - FastAPI 应用

- **角色定位**: 系统的“公共服务窗口”，负责响应来自用户或前端应用的实时数据查询请求。
- **工作原理**:
  - **只读连接**: 在应用启动时，它会建立一个到 DuckDB 元数据文件 (`.db` file) 的**只读连接**。这是非常关键的一点，因为它明确表示“我只负责查询，绝不修改数据”，从而避免了任何意外的数据篡改。
  - **查询流程**: 当一个 API 请求（例如，查询 AAPL 的近期股价）到达时，FastAPI 会将请求转化为 SQL 查询语句，并通过这个只读连接发送给 DuckDB。
  - **数据响应**: DuckDB 引擎根据元数据定位到相关的 Parquet 文件，高效地执行查询，并将结果返回给 FastAPI，最终以 JSON 格式响应给用户。

---

### 核心机制：MVCC 如何确保零中断更新

现在，我们把所有组件串联起来，看看最关键的并发场景是如何工作的。

**场景：后台正在执行每日数据更新，同时一个用户发起了查询请求。**

1.  **写入事务启动**: Huey 任务开始执行。它连接到 `.db` 文件，并发出 `BEGIN TRANSACTION`。此时，DuckDB 在内部创建了一个**新的、临时的数据库版本（快照）**，这个版本只有当前这个写入进程自己能看到。

2.  **查询请求到达**: FastAPI 应用收到查询请求。它使用它的**只读连接**向 DuckDB 发出查询。

3.  **MVCC (多版本并发控制) 发挥作用**:

    - DuckDB 发现有一个正在进行的写入事务，但它尚未提交。
    - 因此，DuckDB 会**忽略**那个正在写入的、未完成的临时版本。
    - 它会引导查询请求去访问**上一个已经成功提交的、稳定的数据库版本**。这个版本是完全一致且完整的。

4.  **并发执行**:

    - **写入进程**: 在自己的隔离环境中，不慌不忙地处理数据，将新的 Parquet 文件写入数据目录，并在内存中更新文件清单。这个过程可能耗时几秒甚至几分钟，但它**完全不会阻塞**读取操作。
    - **读取进程**: 同时，查询请求在稳定的旧版本上快速完成，几乎在瞬间就将结果返回给了用户。用户体验流畅，毫无卡顿。

5.  **写入事务提交**: Huey 任务完成所有数据写入后，执行 `COMMIT`。
    - 这是一个**原子操作**。在这一瞬间，DuckDB 将写入事务所做的所有变更（主要是元数据中文件清单的更新）应用到主版本上，并使其成为新的“稳定版本”。
    - 从这一刻起，**任何新发起**的查询请求都将会看到包含了当天新数据的这个最新版本。

**结论**: 通过 MVCC 机制，DuckDB 巧妙地为读和写提供了不同的“数据视图”，从而实现了完美的隔离。写入操作不会影响正在进行的读取，而读取操作也永远不会看到尚未完成的、不一致的数据。这就是整个架构能够实现零中断更新的核心原理。
