"""Huey ä»»åŠ¡å®šä¹‰

å®šä¹‰å¸¦ @huey_task è£…é¥°å™¨çš„ä¸‹è½½ä»»åŠ¡å‡½æ•°ã€‚
ä½¿ç”¨ä¸­å¿ƒåŒ–çš„å®¹å™¨å®ä¾‹æ¥è·å–ä¾èµ–æœåŠ¡ã€‚
"""

import asyncio
import logging

import pandas as pd
from ..configs.huey_config import huey_fast, huey_slow
from ..task_bus.types import TaskType
from ..helpers.utils import get_next_day_str

logger = logging.getLogger(__name__)


@huey_slow.task()
def build_and_enqueue_downloads_task(group_name: str):
    """æ„å»ºå¹¶æ´¾å‘å¢é‡ä¸‹è½½ä»»åŠ¡ (æ…¢é€Ÿé˜Ÿåˆ—)

    è¿™æ˜¯æ™ºèƒ½å¢é‡ä¸‹è½½çš„ç¬¬ä¸€æ­¥ã€‚
    å®ƒä¼šæŸ¥è¯¢æ•°æ®æ¹–ä¸­å·²æœ‰æ•°æ®çš„æœ€æ–°æ—¥æœŸï¼Œè®¡ç®—å‡ºéœ€è¦ä¸‹è½½çš„èµ·å§‹æ—¥æœŸï¼Œ
    ç„¶åå°†å…·ä½“çš„ä¸‹è½½ä»»åŠ¡æ´¾å‘åˆ°å¿«é€Ÿé˜Ÿåˆ—ã€‚

    Args:
        group_name: åœ¨ groups.toml ä¸­å®šä¹‰çš„ä»»åŠ¡ç»„å
    """
    from ..app import container
    from collections import defaultdict

    logger.info(f"ğŸ› ï¸ [HUEY_SLOW] å¼€å§‹æ„å»ºå¢é‡ä¸‹è½½ä»»åŠ¡, ä»»åŠ¡ç»„: {group_name}")

    group_handler = container.group_handler()
    db_operator = container.db_operator()
    config = container.config()

    try:
        # 1. è§£æä»»åŠ¡ç»„æˆå‘˜
        members = group_handler.get_members(group_name)
        if not members:
            logger.warning(f"ä»»åŠ¡ç»„ '{group_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æˆå‘˜ï¼Œä»»åŠ¡ç»“æŸã€‚")
            return

        # 2. æŒ‰ task_type å¯¹ symbols è¿›è¡Œåˆ†ç»„ï¼Œä¸ºæ‰¹é‡æŸ¥è¯¢åšå‡†å¤‡
        symbols_by_task_type = defaultdict(list)
        for task_type, symbol in members:
            symbols_by_task_type[task_type].append(symbol)

        # 3. æ‰¹é‡æŸ¥è¯¢æ¯ä¸ª task_type ä¸‹æ‰€æœ‰ symbols çš„æœ€æ–°æ—¥æœŸ
        max_dates = {}
        for task_type, symbols in symbols_by_task_type.items():
            logger.debug(f"æ­£åœ¨ä¸º {task_type} æŸ¥è¯¢ {len(symbols)} ä¸ªè‚¡ç¥¨çš„æœ€æ–°æ—¥æœŸ...")
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬å‡è®¾ DBOperator æ˜¯è¿æ¥åˆ°å…ƒæ•°æ®DBçš„
            # åœ¨æ–°æ¶æ„ä¸‹ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ªèƒ½æŸ¥è¯¢ Parquet æ•°æ®æ¹–çš„ DBOperator
            # æ­¤å¤„æš‚æ—¶ä½¿ç”¨ä¸€ä¸ªæ¨¡æ‹Ÿçš„ ParquetDBOperator
            # TODO: æ›¿æ¢ä¸ºçœŸå®çš„ ParquetDBOperator
            from ..database.parquet_operator import ParquetDBOperator
            parquet_op = ParquetDBOperator(config.storage.parquet_base_path)
            max_dates.update(parquet_op.get_max_date(task_type, symbols))

        # 4. å¾ªç¯æ´¾å‘å…·ä½“çš„ä¸‹è½½ä»»åŠ¡
        default_start_date = config.downloader.default_start_date
        enqueued_count = 0
        for task_type, symbol in members:
            latest_date = max_dates.get(symbol)
            start_date = get_next_day_str(latest_date) if latest_date else default_start_date
            
            # æ´¾å‘ä»»åŠ¡åˆ°å¿«é€Ÿé˜Ÿåˆ—
            download_task.call(task_type=task_type, symbol=symbol, start_date=start_date)
            enqueued_count += 1
        
        logger.info(f"âœ… [HUEY_SLOW] æˆåŠŸæ´¾å‘ {enqueued_count} ä¸ªå¢é‡ä¸‹è½½ä»»åŠ¡ã€‚")

    except Exception as e:
        logger.error(f"âŒ [HUEY_SLOW] æ„å»ºä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise e


def _process_data_sync(task_type: str, data: pd.DataFrame) -> bool:
    """å¼‚æ­¥å¤„ç†æ•°æ®çš„å…¬å…±å‡½æ•°

    Args:
        task_type: ä»»åŠ¡ç±»å‹å­—ç¬¦ä¸²
        data: è¦å¤„ç†çš„æ•°æ®

    Returns:
        bool: å¤„ç†æ˜¯å¦æˆåŠŸ
    """
    from ..app import container

    data_processor = container.data_processor()
    try:
        process_success = data_processor.process(task_type, data)
        logger.debug(f"[HUEY] {task_type} æ•°æ®å¤„ç†å™¨è¿”å›ç»“æœ: {process_success}")
        return process_success
    finally:
        # ç¡®ä¿æ•°æ®å¤„ç†å™¨æ­£ç¡®å…³é—­ï¼Œåˆ·æ–°æ‰€æœ‰ç¼“å†²åŒºæ•°æ®
        data_processor.shutdown()


@huey_fast.task()
def download_task(task_type: TaskType, symbol: str, **kwargs):
    """ä¸‹è½½è‚¡ç¥¨æ•°æ®çš„ Huey ä»»åŠ¡ (å¿«é€Ÿé˜Ÿåˆ—)

    ä¸‹è½½å®Œæˆåï¼Œç›´æ¥è°ƒç”¨æ…¢é€Ÿé˜Ÿåˆ—çš„æ•°æ®å¤„ç†ä»»åŠ¡ã€‚

    Args:
        task_type: ä»»åŠ¡ç±»å‹æšä¸¾
        symbol: è‚¡ç¥¨ä»£ç 
        **kwargs: é¢å¤–çš„ä¸‹è½½å‚æ•°ï¼Œå¦‚ start_date, end_date
    """
    try:
        logger.debug(f"ğŸš€ [HUEY_FAST] å¼€å§‹æ‰§è¡Œä¸‹è½½ä»»åŠ¡: {symbol} ({task_type})")

        # ä»ä¸­å¿ƒåŒ–çš„ app.py è·å–å…±äº«çš„å®¹å™¨å®ä¾‹
        from ..app import container

        downloader = container.downloader()

        result = downloader.download(task_type, symbol, **kwargs)

        if result is not None and not result.empty:
            logger.debug(f"ğŸš€ [HUEY_FAST] ä¸‹è½½å®Œæˆ: {symbol}, å‡†å¤‡æäº¤åˆ°æ…¢é€Ÿé˜Ÿåˆ—...")
            # æ‰‹åŠ¨è°ƒç”¨æ…¢é€Ÿä»»åŠ¡ï¼Œå¹¶ä¼ é€’æ•°æ®
            process_data_task(
                task_type=task_type,
                symbol=symbol,
                data_frame=result.to_dict("records"),
            )
        else:
            logger.warning(
                f"âš ï¸ [HUEY_FAST] ä¸‹è½½ä»»åŠ¡å®Œæˆ: {symbol}, ä½†è¿”å›ç©ºæ•°æ®ï¼Œä¸æäº¤åç»­ä»»åŠ¡"
            )

    except Exception as e:
        logger.error(f"âŒ [HUEY_FAST] ä¸‹è½½ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {symbol}, é”™è¯¯: {e}")
        raise e


@huey_slow.task()
def process_data_task(task_type: str, symbol: str, data_frame: list) -> bool:
    """æ•°æ®å¤„ç†ä»»åŠ¡ (æ…¢é€Ÿé˜Ÿåˆ—)

    Args:
        task_type: ä»»åŠ¡ç±»å‹å­—ç¬¦ä¸²
        symbol: è‚¡ç¥¨ä»£ç 
        data_frame: DataFrame æ•°æ® (å­—å…¸åˆ—è¡¨å½¢å¼)

    Returns:
        bool: å¤„ç†æ˜¯å¦æˆåŠŸ
    """
    try:
        # åˆ›å»ºå¼‚æ­¥æ•°æ®å¤„ç†å™¨å¹¶è¿è¡Œ
        def process_sync():
            try:
                # å°†å­—å…¸åˆ—è¡¨è½¬æ¢ä¸º DataFrame
                if data_frame and isinstance(data_frame, list) and len(data_frame) > 0:
                    df_data = pd.DataFrame(data_frame)
                    logger.debug(
                        f"ğŸŒ [HUEY_SLOW] å¼€å§‹å¼‚æ­¥ä¿å­˜æ•°æ®: {symbol}_{task_type}, æ•°æ®è¡Œæ•°: {len(df_data)}"
                    )
                    return _process_data_sync(task_type, df_data)
                else:
                    logger.warning(
                        f"âš ï¸ [HUEY_SLOW] æ•°æ®ä¿å­˜å¤±è´¥ï¼Œæ— æœ‰æ•ˆæ•°æ®: {symbol}_{task_type}, æ•°æ®ä¸ºç©ºæˆ–None"
                    )
                    return False
            except Exception as e:
                raise e

        result = process_sync()
        logger.info(f"ğŸ† [HUEY_SLOW] æœ€ç»ˆç»“æœ: {symbol}_{task_type}, æˆåŠŸ: {result}")
        return result

    except Exception as e:
        logger.error(f"âŒ [HUEY_SLOW] æ•°æ®å¤„ç†ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {symbol}, é”™è¯¯: {e}")
        raise e


# ==========================================================
# å…ƒæ•°æ®åŒæ­¥ä»»åŠ¡ (ç»´æŠ¤é˜Ÿåˆ—)
# ==========================================================
import duckdb
from pathlib import Path
from huey import crontab
from ..configs.huey_config import huey_maint
from ..configs import get_config

config = get_config()


def get_sync_metadata_crontab():
    """ä»é…ç½®ä¸­è¯»å– cron è¡¨è¾¾å¼"""
    schedule = config.cron_tasks.sync_metadata_schedule
    minute, hour, day, month, day_of_week = schedule.split()
    return crontab(minute, hour, day, month, day_of_week)

@huey_maint.periodic_task(get_sync_metadata_crontab(), name="sync_metadata")
def sync_metadata():
    """
    å‘¨æœŸæ€§ä»»åŠ¡ï¼šæ‰«æ Parquet æ–‡ä»¶ç›®å½•ï¼Œå¹¶æ›´æ–° DuckDB å…ƒæ•°æ®æ–‡ä»¶ã€‚
    """
    logger.info("ğŸ› ï¸ [HUEY_MAINT] å¼€å§‹æ‰§è¡Œå…ƒæ•°æ®åŒæ­¥ä»»åŠ¡...")
    
    # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œå¹¶æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
    # neo/tasks/huey_tasks.py -> neo/tasks -> neo -> src -> project_root
    project_root = Path(__file__).resolve().parents[3]
    logger.info(f"è¯Šæ–­: é¡¹ç›®æ ¹ç›®å½•: {project_root}")

    parquet_base_path = project_root / config.storage.parquet_base_path
    metadata_db_path = project_root / config.database.metadata_path
    logger.info(f"è¯Šæ–­: Parquet æ ¹ç›®å½•: {parquet_base_path}")
    logger.info(f"è¯Šæ–­: å…ƒæ•°æ®DBè·¯å¾„: {metadata_db_path}")

    if not parquet_base_path.is_dir():
        logger.warning(f"Parquet æ ¹ç›®å½• {parquet_base_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡åŒæ­¥ã€‚")
        return

    try:
        with duckdb.connect(str(metadata_db_path)) as con:
            logger.info("è¯Šæ–­: æˆåŠŸè¿æ¥åˆ°å…ƒæ•°æ®DBã€‚")
            # æ‰«æ Parquet æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•ï¼Œæ¯ä¸ªå­ç›®å½•ä»£è¡¨ä¸€ä¸ªè¡¨
            
            found_items = list(parquet_base_path.iterdir())
            if not found_items:
                logger.warning(f"è­¦å‘Š: åœ¨ {parquet_base_path} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¡ç›®ã€‚")
                return

            logger.info(f"è¯Šæ–­: åœ¨ {parquet_base_path} ä¸­æ‰¾åˆ°ä»¥ä¸‹æ¡ç›®: {[p.name for p in found_items]}")

            for table_dir in found_items:
                if table_dir.is_dir():
                    table_name = table_dir.name
                    # DuckDB çš„ hive_partitioning ä¼šè‡ªåŠ¨å¤„ç†å­ç›®å½•ï¼Œæˆ‘ä»¬åªéœ€æä¾›æ ¹è·¯å¾„
                    # ä¿®æ­£ï¼šä¸ºå¢å¼ºå…¼å®¹æ€§ï¼Œæˆ‘ä»¬æä¾›ä¸€ä¸ªæ›´æ˜ç¡®çš„ glob è·¯å¾„
                    table_glob_path = str(table_dir / '**/*.parquet')
                    
                    logger.info(f"æ­£åœ¨ä¸ºè¡¨ {table_name} ä»è·¯å¾„ {table_glob_path} åŒæ­¥å…ƒæ•°æ®...")
                    
                    sql = f"""
                    CREATE OR REPLACE TABLE {table_name} AS
                    SELECT * FROM read_parquet('{table_glob_path}', hive_partitioning=1, union_by_name=True);
                    """
                    con.execute(sql)
                    logger.info(f"âœ… è¡¨ {table_name} å…ƒæ•°æ®åŒæ­¥å®Œæˆã€‚")
                else:
                    logger.info(f"è¯Šæ–­: è·³è¿‡éç›®å½•æ¡ç›®: {table_dir}")

        logger.info("ğŸ› ï¸ [HUEY_MAINT] å…ƒæ•°æ®åŒæ­¥ä»»åŠ¡æˆåŠŸå®Œæˆã€‚")
    except Exception as e:
        logger.error(f"âŒ [HUEY_MAINT] å…ƒæ•°æ®åŒæ­¥ä»»åŠ¡å¤±è´¥: {e}")
        raise e
