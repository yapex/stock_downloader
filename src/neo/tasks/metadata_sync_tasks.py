"""å…ƒæ•°æ®åŒæ­¥ä»»åŠ¡æ¨¡å—

åŒ…å« Parquet æ–‡ä»¶å…ƒæ•°æ®åŒæ­¥ç›¸å…³çš„ Huey ä»»åŠ¡ã€‚
"""

import logging
from pathlib import Path
from typing import List, Optional
import os

import duckdb
from huey import crontab
from ..configs.huey_config import huey_maint
from ..configs.app_config import get_config

logger = logging.getLogger(__name__)


class MetadataSyncManager:
    """å…ƒæ•°æ®åŒæ­¥ç®¡ç†å™¨ï¼Œè´Ÿè´£ç®¡ç† Parquet æ–‡ä»¶çš„å…ƒæ•°æ®åŒæ­¥"""

    def __init__(self):
        self.config = get_config()
        self._project_root = None
        self._parquet_base_path = None
        self._metadata_db_path = None

    def _get_project_paths(self) -> tuple[Path, Path, Path]:
        """è·å–é¡¹ç›®ç›¸å…³è·¯å¾„

        Returns:
            tuple[é¡¹ç›®æ ¹ç›®å½•, ParquetåŸºç¡€è·¯å¾„, å…ƒæ•°æ®DBè·¯å¾„]
        """
        if self._project_root is None:
            # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œå¹¶æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
            # neo/tasks/metadata_sync_tasks.py -> neo/tasks -> neo -> src -> project_root
            self._project_root = Path(__file__).resolve().parents[3]
            self._parquet_base_path = (
                self._project_root / self.config.storage.parquet_base_path
            )
            self._metadata_db_path = (
                self._project_root / self.config.database.metadata_path
            )

            logger.debug(f"è¯Šæ–­: é¡¹ç›®æ ¹ç›®å½•: {self._project_root}")
            logger.debug(f"è¯Šæ–­: Parquet æ ¹ç›®å½•: {self._parquet_base_path}")
            logger.debug(f"è¯Šæ–­: å…ƒæ•°æ®DBè·¯å¾„: {self._metadata_db_path}")

        return self._project_root, self._parquet_base_path, self._metadata_db_path

    def _validate_parquet_directory(self, parquet_base_path: Path) -> bool:
        """éªŒè¯ Parquet ç›®å½•æ˜¯å¦å­˜åœ¨

        Args:
            parquet_base_path: Parquet åŸºç¡€è·¯å¾„

        Returns:
            bool: ç›®å½•æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ
        """
        if not parquet_base_path.is_dir():
            logger.warning(f"Parquet æ ¹ç›®å½• {parquet_base_path} ä¸å­˜åœ¨ï¼Œè·³è¿‡åŒæ­¥ã€‚")
            return False
        return True

    def _setup_duckdb_connection(
        self, metadata_db_path: Path
    ) -> duckdb.DuckDBPyConnection:
        """è®¾ç½® DuckDB è¿æ¥å’Œå†…å­˜é™åˆ¶

        Args:
            metadata_db_path: å…ƒæ•°æ®æ•°æ®åº“è·¯å¾„

        Returns:
            DuckDB è¿æ¥å¯¹è±¡
        """
        con = duckdb.connect(str(metadata_db_path))
        # è®¾ç½®DuckDBå†…å­˜é™åˆ¶ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
        con.execute("SET memory_limit='2GB'")
        con.execute("SET max_memory='2GB'")
        logger.info("è¯Šæ–­: æˆåŠŸè¿æ¥åˆ°å…ƒæ•°æ®DBï¼Œå·²è®¾ç½®å†…å­˜é™åˆ¶ä¸º2GBã€‚")
        return con

    def _scan_parquet_directories(self, parquet_base_path: Path) -> List[Path]:
        """æ‰«æ Parquet æ ¹ç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•

        Args:
            parquet_base_path: Parquet åŸºç¡€è·¯å¾„

        Returns:
            List[Path]: æœ‰æ•ˆçš„è¡¨ç›®å½•åˆ—è¡¨
        """
        found_items = list(parquet_base_path.iterdir())
        if not found_items:
            logger.warning(f"è­¦å‘Š: åœ¨ {parquet_base_path} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¡ç›®ã€‚")
            return []

        logger.debug(
            f"è¯Šæ–­: åœ¨ {parquet_base_path} ä¸­æ‰¾åˆ°ä»¥ä¸‹æ¡ç›®: {[p.name for p in found_items]}"
        )

        # åªè¿”å›ç›®å½•
        table_dirs = [item for item in found_items if item.is_dir()]
        logger.debug(f"è¯Šæ–­: æ‰¾åˆ° {len(table_dirs)} ä¸ªè¡¨ç›®å½•")

        return table_dirs

    def _drop_existing_table_or_view(
        self, con: duckdb.DuckDBPyConnection, table_name: str
    ) -> None:
        """åˆ é™¤å·²å­˜åœ¨çš„è¡¨æˆ–è§†å›¾

        Args:
            con: DuckDB è¿æ¥
            table_name: è¡¨å
        """
        try:
            con.execute(f"DROP TABLE IF EXISTS {table_name}")
            con.execute(f"DROP VIEW IF EXISTS {table_name}")
        except Exception as e:
            logger.debug(f"åˆ é™¤è¡¨/è§†å›¾æ—¶å‡ºç°å¼‚å¸¸ï¼ˆå¯å¿½ç•¥ï¼‰: {e}")

    def _validate_parquet_files(self, table_dir: Path) -> List[str]:
        """éªŒè¯ Parquet æ–‡ä»¶çš„æœ‰æ•ˆæ€§

        Args:
            table_dir: è¡¨ç›®å½•è·¯å¾„

        Returns:
            æœ‰æ•ˆçš„ Parquet æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        valid_files = []
        parquet_files = list(table_dir.rglob("*.parquet"))
        
        for file_path in parquet_files:
            try:
                # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼Œç©ºæ–‡ä»¶æˆ–è¿‡å°çš„æ–‡ä»¶å¯èƒ½æŸå
                if file_path.stat().st_size < 100:  # è‡³å°‘100å­—èŠ‚
                    logger.warning(f"è·³è¿‡è¿‡å°çš„æ–‡ä»¶: {file_path}")
                    continue
                
                # å°è¯•ç”¨ DuckDB è¯»å–æ–‡ä»¶å¤´éƒ¨éªŒè¯æ ¼å¼
                with duckdb.connect(":memory:") as test_con:
                    test_con.execute(f"SELECT COUNT(*) FROM read_parquet('{file_path}') LIMIT 1")
                    valid_files.append(str(file_path))
                    
            except Exception as e:
                logger.warning(f"è·³è¿‡æŸåçš„ Parquet æ–‡ä»¶ {file_path}: {e}")
                continue
        
        return valid_files

    def _create_metadata_view(
        self, con: duckdb.DuckDBPyConnection, table_name: str, table_dir: Path
    ) -> None:
        """åˆ›å»ºå…ƒæ•°æ®è§†å›¾

        Args:
            con: DuckDB è¿æ¥
            table_name: è¡¨å
            table_dir: è¡¨ç›®å½•è·¯å¾„
        """
        logger.debug(f"æ­£åœ¨ä¸ºè¡¨ {table_name} ä»ç›®å½• {table_dir} åŒæ­¥å…ƒæ•°æ®...")

        # éªŒè¯ Parquet æ–‡ä»¶
        valid_files = self._validate_parquet_files(table_dir)
        
        if not valid_files:
            logger.warning(f"è¡¨ {table_name} æ²¡æœ‰æœ‰æ•ˆçš„ Parquet æ–‡ä»¶ï¼Œè·³è¿‡è§†å›¾åˆ›å»º")
            return
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„åˆ—è¡¨ç”¨äº read_parquet
        files_str = "[" + ", ".join(f"'{f}'" for f in valid_files) + "]"
        
        # ä½¿ç”¨VIEWè€Œä¸æ˜¯TABLEï¼Œé¿å…å°†æ‰€æœ‰æ•°æ®åŠ è½½åˆ°å†…å­˜
        # VIEWåªå­˜å‚¨æŸ¥è¯¢å®šä¹‰ï¼Œä¸å­˜å‚¨å®é™…æ•°æ®
        # ä½¿ç”¨ CREATE OR REPLACE VIEW é¿å…è§†å›¾å·²å­˜åœ¨çš„é”™è¯¯
        sql = f"""
        CREATE OR REPLACE VIEW {table_name} AS
        SELECT * FROM read_parquet({files_str}, hive_partitioning=1, union_by_name=True);
        """
        con.execute(sql)
        logger.info(f"âœ… è¡¨ {table_name} å…ƒæ•°æ®è§†å›¾åŒæ­¥å®Œæˆï¼ŒåŒ…å« {len(valid_files)} ä¸ªæœ‰æ•ˆæ–‡ä»¶ã€‚")

    def _sync_table_metadata(
        self, con: duckdb.DuckDBPyConnection, table_dir: Path
    ) -> None:
        """åŒæ­¥å•ä¸ªè¡¨çš„å…ƒæ•°æ®

        Args:
            con: DuckDB è¿æ¥
            table_dir: è¡¨ç›®å½•è·¯å¾„
        """
        table_name = table_dir.name

        # å…ˆåˆ é™¤å¯èƒ½å­˜åœ¨çš„TABLEæˆ–VIEWï¼Œé¿å…ç±»å‹å†²çª
        self._drop_existing_table_or_view(con, table_name)

        # åˆ›å»ºæ–°çš„è§†å›¾
        self._create_metadata_view(con, table_name, table_dir)

    def sync_metadata(self) -> None:
        """æ‰§è¡Œå…ƒæ•°æ®åŒæ­¥çš„ä¸»è¦æ–¹æ³•"""
        logger.info("ğŸ› ï¸ [HUEY_MAINT] å¼€å§‹æ‰§è¡Œå…ƒæ•°æ®åŒæ­¥ä»»åŠ¡...")

        try:
            # 1. è·å–é¡¹ç›®è·¯å¾„
            project_root, parquet_base_path, metadata_db_path = (
                self._get_project_paths()
            )

            # 2. éªŒè¯ Parquet ç›®å½•
            if not self._validate_parquet_directory(parquet_base_path):
                return

            # 3. è®¾ç½®æ•°æ®åº“è¿æ¥
            with self._setup_duckdb_connection(metadata_db_path) as con:
                # 4. æ‰«æè¡¨ç›®å½•
                table_dirs = self._scan_parquet_directories(parquet_base_path)
                if not table_dirs:
                    return

                # 5. åŒæ­¥æ¯ä¸ªè¡¨çš„å…ƒæ•°æ®
                for table_dir in table_dirs:
                    self._sync_table_metadata(con, table_dir)

            logger.info("ğŸ› ï¸ [HUEY_MAINT] å…ƒæ•°æ®åŒæ­¥ä»»åŠ¡æˆåŠŸå®Œæˆã€‚")

        except Exception as e:
            logger.error(f"âŒ [HUEY_MAINT] å…ƒæ•°æ®åŒæ­¥ä»»åŠ¡å¤±è´¥: {e}")
            raise e


def get_sync_metadata_crontab():
    """ä»é…ç½®ä¸­è¯»å– cron è¡¨è¾¾å¼"""
    config = get_config()
    schedule = config.cron_tasks.sync_metadata_schedule
    minute, hour, day, month, day_of_week = schedule.split()
    return crontab(minute, hour, day, month, day_of_week)


@huey_maint.periodic_task(get_sync_metadata_crontab(), name="sync_metadata")
def sync_metadata():
    """
    å‘¨æœŸæ€§ä»»åŠ¡ï¼šæ‰«æ Parquet æ–‡ä»¶ç›®å½•ï¼Œå¹¶æ›´æ–° DuckDB å…ƒæ•°æ®æ–‡ä»¶ã€‚
    """
    sync_manager = MetadataSyncManager()
    sync_manager.sync_metadata()
