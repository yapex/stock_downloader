"""ä¸‹è½½ä»»åŠ¡æ¨¡å—

åŒ…å«è‚¡ç¥¨æ•°æ®ä¸‹è½½ç›¸å…³çš„ Huey ä»»åŠ¡ã€‚
V3ç‰ˆæœ¬é‡‡ç”¨äº¤å‰ç”Ÿæˆå’Œéšæœºä¼˜å…ˆçº§ç­–ç•¥ï¼Œä»¥ä¼˜åŒ–ä»»åŠ¡é˜Ÿåˆ—çš„å‡åŒ€æ€§ã€è§£å†³â€œè½¦é˜Ÿæ•ˆåº”â€å¹¶å‡å°‘å†…å­˜å ç”¨ã€‚
"""

import logging
import random
from datetime import datetime, time, timedelta
from typing import Dict, Iterator, List, Optional, Tuple, TYPE_CHECKING

from ..configs.app_config import get_config
from ..configs.huey_config import huey_fast, huey_slow
from ..helpers.utils import get_next_day_str

if TYPE_CHECKING:
    from ..database.operator import ParquetDBQueryer
    from ..database.interfaces import ISchemaLoader

logger = logging.getLogger(__name__)


class DownloadTaskManager:
    """ä¸‹è½½ä»»åŠ¡ç®¡ç†å™¨ï¼Œè´Ÿè´£æ„å»ºå’Œç®¡ç†ä¸‹è½½ä»»åŠ¡ (æ— çŠ¶æ€)"""

    def __init__(self, schema_loader: "ISchemaLoader"):
        self.config = get_config()
        self.schema_loader = schema_loader

    def _get_task_types_and_symbols(
        self, group_name: str, stock_codes: Optional[List[str]]
    ) -> Tuple[List[str], Optional[List[str]]]:
        """è·å–ä»»åŠ¡ç±»å‹å’Œè‚¡ç¥¨ä»£ç åˆ—è¡¨"""
        from ..app import container

        group_handler = container.group_handler()
        logger.debug(f"è·å–åˆ° group_handler: {group_handler}")

        task_types = group_handler.get_task_types_for_group(group_name)
        logger.debug(f"è·å–åˆ° task_types: {task_types}")
        if not task_types:
            logger.warning(f"ä»»åŠ¡ç»„ '{group_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä»»åŠ¡ç±»å‹ï¼Œä»»åŠ¡ç»“æŸã€‚")
            return [], None

        if stock_codes:
            symbols = stock_codes
            logger.debug(f"ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„è‚¡ç¥¨ä»£ç : {len(symbols)} ä¸ª")
        else:
            symbols = group_handler.get_symbols_for_group(group_name)
            logger.debug(
                f"ä½¿ç”¨ä»»åŠ¡ç»„ '{group_name}' é…ç½®çš„è‚¡ç¥¨ä»£ç : {len(symbols) if symbols else 0} ä¸ª"
            )

        return task_types, symbols

    def _should_skip_task(
        self, latest_date: Optional[str], latest_trading_day: Optional[str]
    ) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡å½“å‰ä»»åŠ¡"""
        if not latest_date:
            return False

        if not latest_trading_day:
            logger.warning("æ— æ³•è·å–æœ€æ–°äº¤æ˜“æ—¥ï¼Œä½¿ç”¨æ—§é€»è¾‘è¿›è¡Œåˆ¤æ–­ã€‚")
            today_str = datetime.now().strftime("%Y%m%d")
            yesterday_str = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
            current_time = datetime.now().time()
            market_close_time = time(18, 0)

            if latest_date == today_str:
                return True
            if latest_date == yesterday_str and current_time < market_close_time:
                return True
            return False

        if latest_date < latest_trading_day:
            logger.info(
                f"ğŸ“¥ æ‰§è¡Œä»»åŠ¡ï¼šæœ¬åœ°æ•°æ®è½å (æœ¬åœ°: {latest_date}, æœ€æ–°äº¤æ˜“æ—¥: {latest_trading_day})"
            )
            return False

        if latest_date > latest_trading_day:
            logger.info(
                f"â­ï¸ è·³è¿‡ä»»åŠ¡ï¼šæ•°æ®å·²æ˜¯æœ€æ–° (æœ¬åœ°: {latest_date}, æœ€æ–°äº¤æ˜“æ—¥: {latest_trading_day})"
            )
            return True

        today_str = datetime.now().strftime("%Y%m%d")
        if today_str == latest_trading_day:
            current_time = datetime.now().time()
            market_close_time = time(18, 0)
            if current_time < market_close_time:
                logger.info(
                    f"â­ï¸ è·³è¿‡ä»»åŠ¡ï¼šç­‰å¾… {latest_trading_day} æ”¶ç›˜æ•°æ® (æœ¬åœ°: {latest_date}, å½“å‰æ—¶é—´: {current_time.strftime('%H:%M')})"
                )
                return True
            else:
                logger.info(
                    f"ğŸ“¥ æ‰§è¡Œä»»åŠ¡ï¼š{latest_trading_day} å·²æ”¶ç›˜ï¼Œä¸‹è½½ä»Šæ—¥æ•°æ® (æœ¬åœ°: {latest_date})"
                )
                return False
        else:
            logger.info(
                f"â­ï¸ è·³è¿‡ä»»åŠ¡ï¼šæ•°æ®å·²æ˜¯æœ€æ–° (æœ¬åœ°: {latest_date}, æœ€æ–°äº¤æ˜“æ—¥: {latest_trading_day})"
            )
            return True

    def _generate_task_configs_for_type(
        self,
        task_type: str,
        symbols: Optional[List[str]],
        db_queryer: "ParquetDBQueryer",
        latest_trading_day: Optional[str],
    ) -> Iterator[Dict]:
        """ä¸ºä¸€ä¸ªä»»åŠ¡ç±»å‹åˆ›å»ºæ‰€æœ‰ä»»åŠ¡é…ç½®çš„ç”Ÿæˆå™¨"""
        logger.debug(f"ä¸ºä»»åŠ¡ç±»å‹ '{task_type}' åˆ›å»ºä»»åŠ¡ç”Ÿæˆå™¨...")
        default_start_date = self.config.download_tasks.default_start_date

        try:
            table_config = self.schema_loader.get_table_config(task_type)
            has_date_col = (
                hasattr(table_config, "date_col") and table_config.date_col is not None
            )
        except (KeyError, AttributeError):
            has_date_col = False

        task_symbols = symbols if symbols is not None else [""]

        if has_date_col:
            max_dates = db_queryer.get_max_date(task_type, task_symbols)
            for symbol in task_symbols:
                latest_date = max_dates.get(symbol)
                if self._should_skip_task(latest_date, latest_trading_day):
                    continue
                start_date = (
                    get_next_day_str(latest_date) if latest_date else default_start_date
                )
                yield {
                    "task_type": task_type,
                    "symbol": symbol,
                    "start_date": start_date,
                }
        else:  # æ²¡æœ‰æ—¥æœŸåˆ—çš„ä»»åŠ¡ç±»å‹ï¼ˆå¦‚ stock_basicï¼‰ï¼Œæ€»æ˜¯æ‰§è¡Œ
            for symbol in task_symbols:
                yield {
                    "task_type": task_type,
                    "symbol": symbol,
                    "start_date": default_start_date,
                }


@huey_slow.task()
def build_and_enqueue_downloads_task(
    group_name: str, stock_codes: Optional[List[str]] = None
):
    """
    æ„å»ºå¹¶æ´¾å‘å¢é‡ä¸‹è½½ä»»åŠ¡ (æ…¢é€Ÿé˜Ÿåˆ—, V3 - éšæœºä¼˜å…ˆçº§)

    è¿™æ˜¯æ™ºèƒ½å¢é‡ä¸‹è½½çš„ç¬¬ä¸€æ­¥ã€‚å®ƒä¼šä¸ºæ¯ä¸ªä¸šåŠ¡ç±»å‹åˆ›å»ºç‹¬ç«‹çš„ä»»åŠ¡ç”Ÿæˆå™¨ï¼Œ
    ç„¶åé€šè¿‡è½®è¯¢ã€äº¤å‰ç”Ÿæˆçš„æ–¹å¼ï¼Œä¸ºæ¯ä¸ªä»»åŠ¡é™„åŠ ä¸€ä¸ªéšæœºä¼˜å…ˆçº§åå†æ´¾å‘ã€‚
    è¿™èƒ½ç¡®ä¿é˜Ÿåˆ—ä»»åŠ¡çš„é«˜åº¦å¤šæ ·æ€§ï¼Œè§£å†³â€œè½¦é˜Ÿæ•ˆåº”â€å¯¼è‡´çš„ worker é˜»å¡ã€‚

    Args:
        group_name: åœ¨ config.toml ä¸­å®šä¹‰çš„ä»»åŠ¡ç»„å
        stock_codes: å¯é€‰çš„è‚¡ç¥¨ä»£ç åˆ—è¡¨ï¼Œå¦‚æœæä¾›åˆ™åªå¤„ç†è¿™äº›è‚¡ç¥¨
    """
    logger.debug(f"ğŸ› ï¸ [HUEY_SLOW] V3 å¼€å§‹æ„å»ºå¢é‡ä¸‹è½½ä»»åŠ¡, ä»»åŠ¡ç»„: {group_name}")
    try:
        from ..app import container

        db_queryer = container.db_queryer()
        schema_loader = container.schema_loader()
        task_manager = DownloadTaskManager(schema_loader)

        latest_trading_day = db_queryer.get_latest_trading_day()
        if latest_trading_day:
            logger.debug(f"è·å–åˆ°æœ€æ–°äº¤æ˜“æ—¥: {latest_trading_day}")
        else:
            logger.warning("æœªèƒ½è·å–åˆ°æœ€æ–°äº¤æ˜“æ—¥ï¼Œéƒ¨åˆ†ä»»åŠ¡å¯èƒ½ä¸ä¼šæ‰§è¡Œå¢é‡æ£€æŸ¥ã€‚")

        task_types, symbols = task_manager._get_task_types_and_symbols(
            group_name, stock_codes
        )
        if not task_types:
            return

        # 1. ä¸ºæ¯ä¸ªä¸šåŠ¡ç±»å‹åˆ›å»ºç‹¬ç«‹çš„â€œä»»åŠ¡ç”Ÿæˆå™¨â€
        logger.info(f"ä¸º {len(task_types)} ä¸ªä»»åŠ¡ç±»å‹åˆ›å»ºç”Ÿæˆå™¨: {task_types}")
        generators = [
            task_manager._generate_task_configs_for_type(
                tt, symbols, db_queryer, latest_trading_day
            )
            for tt in task_types
        ]

        # 2. è½®è¯¢ã€äº¤å‰ç”Ÿæˆå¹¶æ´¾å‘å¸¦æœ‰éšæœºä¼˜å…ˆçº§çš„ä»»åŠ¡
        enqueued_count = 0
        active_generators = [iter(g) for g in generators]
        logger.debug(f"å¼€å§‹ä» {len(active_generators)} ä¸ªç”Ÿæˆå™¨ä¸­è½®è¯¢å¹¶æ´¾å‘ä»»åŠ¡...")

        while active_generators:
            # å€’åºéå†ï¼Œæ–¹ä¾¿å®‰å…¨åœ°ç§»é™¤è€—å°½çš„ç”Ÿæˆå™¨
            for i in range(len(active_generators) - 1, -1, -1):
                gen_iter = active_generators[i]
                try:
                    task_params = next(gen_iter)
                    # æ´¾å‘ä»»åŠ¡ï¼Œå¹¶é™„åŠ ä¸€ä¸ª0-9ä¹‹é—´çš„éšæœºä¼˜å…ˆçº§
                    # Huey ä¼šä¼˜å…ˆæ‰§è¡Œ priority å€¼é«˜çš„ä»»åŠ¡
                    download_task(priority=random.randint(0, 9), **task_params)
                    enqueued_count += 1
                except StopIteration:
                    # è¿™ä¸ªç”Ÿæˆå™¨å·²ç»è€—å°½ï¼Œå°†å®ƒä»æ´»è·ƒåˆ—è¡¨ä¸­ç§»é™¤
                    active_generators.pop(i)

        logger.debug(f"âœ… [HUEY_SLOW] V3 æˆåŠŸæ´¾å‘ {enqueued_count} ä¸ªå¢é‡ä¸‹è½½ä»»åŠ¡ã€‚")

    except Exception as e:
        logger.error(f"âŒ [HUEY_SLOW] V3 æ„å»ºä¸‹è½½ä»»åŠ¡å¤±è´¥: {e}", exc_info=True)
        raise e


@huey_fast.task(retries=2, retry_delay=60)
def download_task(task_type: str, symbol: str, **kwargs):
    """
    ä¸‹è½½è‚¡ç¥¨æ•°æ®çš„ Huey ä»»åŠ¡ (å¿«é€Ÿé˜Ÿåˆ—)

    ä¸‹è½½å®Œæˆåï¼Œç›´æ¥è°ƒç”¨æ…¢é€Ÿé˜Ÿåˆ—çš„æ•°æ®å¤„ç†ä»»åŠ¡ã€‚

    Args:
        task_type: ä»»åŠ¡ç±»å‹å­—ç¬¦ä¸²
        symbol: è‚¡ç¥¨ä»£ç 
        **kwargs: é¢å¤–çš„ä¸‹è½½å‚æ•°ï¼Œå¦‚ start_date, end_date
    """
    try:
        logger.debug(f"ğŸš€ [HUEY_FAST] å¼€å§‹æ‰§è¡Œä¸‹è½½ä»»åŠ¡: {symbol} ({task_type})")

        from ..app import container
        from .data_processing_tasks import process_data_task

        downloader = container.downloader()
        result = downloader.download(task_type, symbol, **kwargs)

        if result is not None and not result.empty:
            logger.info(f"ğŸš€ [HUEY_FAST] ä¸‹è½½å®Œæˆ: {symbol}, å‡†å¤‡æäº¤åˆ°æ…¢é€Ÿé˜Ÿåˆ—...")
            process_data_task(
                task_type=task_type,
                symbol=symbol,
                data_frame=result.to_dict("records"),
            )
        else:
            logger.warning(
                f"âš ï¸ [HUEY_FAST] ä¸‹è½½ä»»åŠ¡å®Œæˆ: {symbol}, ä½†è¿”å›ç©ºæ•°æ®ï¼Œä¸æäº¤åç»­ä»»åŠ¡"
            )

    except Exception as e:
        logger.error(
            f"âŒ [HUEY_FAST] ä¸‹è½½ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œå°†åœ¨60ç§’åé‡è¯•ã€‚ä»»åŠ¡: {task_type}, ä»£ç : {symbol}, é”™è¯¯: {e}",
            exc_info=True,
        )
        raise e


@huey_slow.task()
def cleanup_downloader_task():
    """æ¸…ç†ä¸‹è½½å™¨èµ„æº"""
    from ..app import container

    downloader = container.downloader()
    if hasattr(downloader, "cleanup"):
        downloader.cleanup()
    logger.info("Downloader resources cleaned up.")
