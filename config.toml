[huey_fast]
max_workers = 8  # 减少worker数量以避免超过API限制
sqlite_path = "data/tasks_fast.db"

[huey_slow]
max_workers = 1   # 为慢速队列分配少量worker
sqlite_path = "data/tasks_slow.db"

[huey_maint]
max_workers = 1
sqlite_path = "data/tasks_maint.db"

[storage]
parquet_base_path = "data/parquet"

[database]
type = "duckdb"
path = "data/stock.db" # 旧的、包含物理数据的主数据库
metadata_path = "data/metadata.db" # 新的、仅含元数据的数据库
schema_file_path = "stock_schema.toml" # 相对于项目根目录

[cron_tasks]
sync_metadata_schedule = "*/10 * * * *" # 每10分钟执行一次

[download_tasks]
default_start_date = "19900101"

# 注意：这里的键名必须与表名一致
[download_tasks.stock_basic]
rate_limit_per_minute = 195  
update_strategy = "full_replace"  # 全量替换策略，避免重复数据
# 交易日历
[download_tasks.trade_cal]
rate_limit_per_minute = 195  
update_strategy = "full_replace"  # 全量替换策略，避免重复数据

[download_tasks.stock_daily]
rate_limit_per_minute = 195
# update_strategy = "incremental"
update_strategy = "full_replace"  # 全量替换策略，避免重复数据

[download_tasks.stock_adj_hfq]
rate_limit_per_minute = 195
# update_strategy = "incremental"
update_strategy = "full_replace"  # 全量替换策略，避免重复数据  

[download_tasks.daily_basic] 
rate_limit_per_minute = 195
# update_strategy = "incremental"
update_strategy = "full_replace"  # 全量替换策略，避免重复数据

[download_tasks.balance_sheet]  
rate_limit_per_minute = 195  
# update_strategy = "incremental"
update_strategy = "full_replace"  # 全量替换策略，避免重复数据

[download_tasks.income]  
rate_limit_per_minute = 195  
# update_strategy = "incremental"
update_strategy = "full_replace"  # 全量替换策略，避免重复数据

[download_tasks.cash_flow]  
rate_limit_per_minute = 195  
# update_strategy = "incremental"
update_strategy = "full_replace"  # 全量替换策略，避免重复数据

[task_groups]
sys=[
    "stock_basic",
    "trade_cal"
]
daily = [
    "stock_daily",
    "daily_basic",
    "stock_adj_hfq"
]
financial=[
    "balance_sheet",
    "income",
    "cash_flow",
]
all=[
    "stock_daily",
    "daily_basic",
    "stock_adj_hfq",
    "balance_sheet",
    "income",
    "cash_flow",
]
test=[
    "daily_basic"
]
