#!/usr/bin/env python3
"""
åŸºäºSchemaçš„æ•°æ®æ“ä½œç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨åŠ¨æ€è¡¨åˆ›å»ºå™¨è¿›è¡Œæ•°æ®æ’å…¥å’ŒæŸ¥è¯¢æ“ä½œ
"""

import pandas as pd
from schema_driven_table_creator import SchemaTableCreator


class SchemaDataOperator:
    """åŸºäºSchemaçš„æ•°æ®æ“ä½œå™¨"""
    
    def __init__(self, schema_file_path: str, db_path: str = ":memory:"):
        self.creator = SchemaTableCreator(schema_file_path, db_path)
        self.conn = None
        
    def _extract_column_names(self, columns) -> list:
        """
        ä»columnsé…ç½®ä¸­æå–å­—æ®µååˆ—è¡¨
        
        Args:
            columns: å­—æ®µé…ç½®ï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æˆ–åŒ…å«name/typeçš„å­—å…¸åˆ—è¡¨
            
        Returns:
            å­—æ®µååˆ—è¡¨
        """
        column_names = []
        for col in columns:
            if isinstance(col, dict) and 'name' in col:
                # æ–°æ ¼å¼ï¼š{name: "å­—æ®µå", type: "ç±»å‹"}
                column_names.append(col['name'])
            else:
                # å…¼å®¹æ—§æ ¼å¼ï¼šç›´æ¥æ˜¯å­—ç¬¦ä¸²
                column_names.append(col)
        return column_names
        
    def initialize(self):
        """åˆå§‹åŒ–ï¼šåŠ è½½schemaã€è¿æ¥æ•°æ®åº“ã€åˆ›å»ºè¡¨"""
        print("ğŸš€ åˆå§‹åŒ–æ•°æ®æ“ä½œå™¨...")
        
        # åŠ è½½schema
        self.creator.load_schema()
        print(f"âœ… åŠ è½½äº† {len(self.creator.schema_config)} ä¸ªè¡¨é…ç½®")
        
        # è¿æ¥æ•°æ®åº“
        self.conn = self.creator.connect_db()
        print("âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ")
        
        # åˆ›å»ºæ‰€æœ‰è¡¨
        results = self.creator.create_all_tables()
        success_count = sum(1 for success in results.values() if success)
        print(f"âœ… æˆåŠŸåˆ›å»º {success_count}/{len(results)} ä¸ªè¡¨")
        
    def insert_sample_data(self, table_name: str, data: pd.DataFrame):
        """æ’å…¥ç¤ºä¾‹æ•°æ®"""
        if not self.conn:
            raise ValueError("è¯·å…ˆåˆå§‹åŒ–")
            
        try:
            # æ³¨å†ŒDataFrameåˆ°DuckDB
            temp_view_name = f"temp_{table_name}"
            self.conn.register(temp_view_name, data)
            
            # è·å–è¡¨çš„å®é™…åç§°
            table_config = self.creator.schema_config[table_name]
            actual_table_name = table_config.table_name
            
            # æ’å…¥æ•°æ®
            columns = ", ".join(data.columns)
            insert_sql = f"""
            INSERT INTO {actual_table_name} ({columns})
            SELECT {columns} FROM {temp_view_name}
            """
            
            self.conn.execute(insert_sql)
            
            # æ¸…ç†ä¸´æ—¶è§†å›¾
            self.conn.unregister(temp_view_name)
            
            print(f"âœ… æˆåŠŸæ’å…¥ {len(data)} æ¡è®°å½•åˆ°è¡¨ {actual_table_name}")
            
        except Exception as e:
            print(f"âŒ æ’å…¥æ•°æ®å¤±è´¥: {e}")
            
    def query_data(self, table_name: str, limit: int = 10) -> pd.DataFrame:
        """æŸ¥è¯¢æ•°æ®"""
        if not self.conn:
            raise ValueError("è¯·å…ˆåˆå§‹åŒ–")
            
        table_config = self.creator.schema_config[table_name]
        actual_table_name = table_config.table_name
        
        sql = f"SELECT * FROM {actual_table_name} LIMIT {limit}"
        result = self.conn.execute(sql).fetchdf()
        
        print(f"ğŸ“Š ä»è¡¨ {actual_table_name} æŸ¥è¯¢åˆ° {len(result)} æ¡è®°å½•")
        return result
        
    def get_table_stats(self, table_name: str):
        """è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        if not self.conn:
            raise ValueError("è¯·å…ˆåˆå§‹åŒ–")
            
        table_config = self.creator.schema_config[table_name]
        actual_table_name = table_config.table_name
        
        # è·å–è®°å½•æ•°
        count_sql = f"SELECT COUNT(*) as count FROM {actual_table_name}"
        count_result = self.conn.execute(count_sql).fetchone()
        record_count = count_result[0] if count_result else 0
        
        print(f"ğŸ“ˆ è¡¨ {actual_table_name} ç»Ÿè®¡ä¿¡æ¯:")
        print(f"  - è®°å½•æ•°: {record_count}")
        print(f"  - ä¸»é”®: {table_config.primary_key}")
        print(f"  - å­—æ®µæ•°: {len(table_config.columns)}")
        
        return {
            'table_name': actual_table_name,
            'record_count': record_count,
            'primary_key': table_config.primary_key,
            'column_count': len(table_config.columns)
        }
        
    def upsert_data(self, table_key: str, data: pd.DataFrame):
        """
        ä½¿ç”¨ä¸´æ—¶è¡¨å’ŒINSERT ... ON CONFLICTè¯­å¥å‘æŒ‡å®šè¡¨æ›´æ–°æˆ–æ’å…¥æ•°æ® (Upsert)ã€‚
        
        Args:
            table_key: è¡¨åœ¨schemaé…ç½®ä¸­çš„é”®å (e.g., 'stock_basic')
            data: åŒ…å«æ–°æ•°æ®çš„Pandas DataFrame
        """
        if data.empty:
            print(f"â„¹ï¸ æ•°æ®æºä¸ºç©ºï¼Œè·³è¿‡å¯¹è¡¨ '{table_key}' çš„æ“ä½œã€‚")
            return

        table_config = self.creator.schema_config[table_key]
        table_name = table_config.table_name
        primary_keys = table_config.primary_key
        columns = self._extract_column_names(table_config.columns)
        
        if not primary_keys:
            raise ValueError(f"è¡¨ '{table_name}' æœªå®šä¹‰ä¸»é”®ï¼Œæ— æ³•æ‰§è¡Œ upsert æ“ä½œã€‚")

        # æ ¡éªŒDataFrameæ˜¯å¦åŒ…å«æ‰€æœ‰schemaå®šä¹‰çš„åˆ—
        missing_cols = set(columns) - set(data.columns)
        if missing_cols:
            raise ValueError(f"DataFrame ç¼ºå°‘ä»¥ä¸‹åˆ—: {missing_cols}")

        try:
            self.conn.execute("BEGIN TRANSACTION;")
            
            if len(data) == 1:
                # å•æ¡æ•°æ®ç›´æ¥æ’å…¥
                self._upsert_single_record(table_name, primary_keys, columns, data)
            else:
                # å¤šæ¡æ•°æ®ä½¿ç”¨ä¸´æ—¶è¡¨æ‰¹é‡å¤„ç†
                self._upsert_batch_records(table_key, table_name, primary_keys, columns, data)
            
            self.conn.execute("COMMIT;")
            print(f"âœ… æˆåŠŸå¯¹è¡¨ {table_name} æ‰§è¡Œäº† Upsert æ“ä½œï¼Œå¤„ç†äº† {len(data)} æ¡è®°å½•ã€‚")
            
        except Exception as e:
            self.conn.execute("ROLLBACK;")
            print(f"âŒ å¯¹è¡¨ {table_name} æ‰§è¡Œ Upsert å¤±è´¥: {e}")
            raise
    
    def _upsert_single_record(self, table_name: str, primary_keys: list, columns: list, data: pd.DataFrame):
        """å¤„ç†å•æ¡è®°å½•çš„upsertæ“ä½œ"""
        # æ„å»ºINSERT ... ON CONFLICTè¯­å¥
        columns_str = ", ".join(f'"{c}"' for c in columns)
        values_str = ", ".join(["?" for _ in columns])
        primary_keys_str = ", ".join(f'"{pk}"' for pk in primary_keys)
        
        update_columns = [col for col in columns if col not in primary_keys]
        update_set = ", ".join([f'"{col}" = EXCLUDED."{col}"' for col in update_columns])
        
        if update_set:  # å¦‚æœæœ‰éä¸»é”®å­—æ®µéœ€è¦æ›´æ–°
            sql = f"""
            INSERT INTO {table_name} ({columns_str})
            VALUES ({values_str})
            ON CONFLICT ({primary_keys_str}) DO UPDATE SET {update_set}
            """
        else:  # å¦‚æœåªæœ‰ä¸»é”®å­—æ®µï¼Œä½¿ç”¨DO NOTHING
            sql = f"""
            INSERT INTO {table_name} ({columns_str})
            VALUES ({values_str})
            ON CONFLICT ({primary_keys_str}) DO NOTHING
            """
        
        # è·å–æ•°æ®å€¼
        values = [data.iloc[0][col] for col in columns]
        self.conn.execute(sql, values)
    
    def _upsert_batch_records(self, table_key: str, table_name: str, primary_keys: list, columns: list, data: pd.DataFrame):
        """å¤„ç†æ‰¹é‡è®°å½•çš„upsertæ“ä½œï¼Œä½¿ç”¨ä¸´æ—¶è¡¨"""
        temp_table_name = f"temp_upsert_{table_key}_{id(data)}"
        
        try:
            # 1. åˆ›å»ºä¸´æ—¶è¡¨
            columns_def = ", ".join([f'"{col}" VARCHAR' for col in columns])
            create_temp_sql = f"CREATE TEMPORARY TABLE {temp_table_name} ({columns_def})"
            self.conn.execute(create_temp_sql)
            
            # 2. å°†æ•°æ®æ’å…¥ä¸´æ—¶è¡¨
            temp_view_name = f"temp_view_{table_key}"
            self.conn.register(temp_view_name, data)
            
            columns_str = ", ".join(f'"{c}"' for c in columns)
            insert_temp_sql = f"""
            INSERT INTO {temp_table_name} ({columns_str})
            SELECT {columns_str} FROM {temp_view_name}
            """
            self.conn.execute(insert_temp_sql)
            
            # 3. ä½¿ç”¨INSERT ... ON CONFLICTè¿›è¡Œupsert
            primary_keys_str = ", ".join(f'"{pk}"' for pk in primary_keys)
            update_columns = [col for col in columns if col not in primary_keys]
            
            if update_columns:  # å¦‚æœæœ‰éä¸»é”®å­—æ®µéœ€è¦æ›´æ–°
                update_set = ", ".join([f'"{col}" = EXCLUDED."{col}"' for col in update_columns])
                upsert_sql = f"""
                INSERT INTO {table_name} ({columns_str})
                SELECT {columns_str} FROM {temp_table_name}
                ON CONFLICT ({primary_keys_str}) DO UPDATE SET {update_set}
                """
            else:  # å¦‚æœåªæœ‰ä¸»é”®å­—æ®µï¼Œä½¿ç”¨DO NOTHING
                upsert_sql = f"""
                INSERT INTO {table_name} ({columns_str})
                SELECT {columns_str} FROM {temp_table_name}
                ON CONFLICT ({primary_keys_str}) DO NOTHING
                """
            
            self.conn.execute(upsert_sql)
            
            # 4. æ¸…ç†ä¸´æ—¶èµ„æº
            self.conn.unregister(temp_view_name)
            
        finally:
            # ç¡®ä¿ä¸´æ—¶è¡¨è¢«åˆ é™¤
            try:
                self.conn.execute(f"DROP TABLE IF EXISTS {temp_table_name}")
            except:
                pass
            
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.creator:
            self.creator.close()


def create_sample_stock_basic_data() -> pd.DataFrame:
    """åˆ›å»ºç¤ºä¾‹è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®"""
    data = {
        'ts_code': ['000001.SZ', '000002.SZ', '600000.SH'],
        'symbol': ['000001', '000002', '600000'],
        'name': ['å¹³å®‰é“¶è¡Œ', 'ä¸‡ç§‘A', 'æµ¦å‘é“¶è¡Œ'],
        'area': ['æ·±åœ³', 'æ·±åœ³', 'ä¸Šæµ·'],
        'industry': ['é“¶è¡Œ', 'æˆ¿åœ°äº§', 'é“¶è¡Œ'],
        'cnspell': ['PAYH', 'WKA', 'PFYH'],
        'market': ['ä¸»æ¿', 'ä¸»æ¿', 'ä¸»æ¿'],
        'list_date': ['19910403', '19910129', '19991110'],
        'act_name': ['å¹³å®‰é“¶è¡Œè‚¡ä»½æœ‰é™å…¬å¸', 'ä¸‡ç§‘ä¼ä¸šè‚¡ä»½æœ‰é™å…¬å¸', 'ä¸Šæµ·æµ¦ä¸œå‘å±•é“¶è¡Œè‚¡ä»½æœ‰é™å…¬å¸'],
        'act_ent_type': ['è‚¡ä»½æœ‰é™å…¬å¸', 'è‚¡ä»½æœ‰é™å…¬å¸', 'è‚¡ä»½æœ‰é™å…¬å¸']
    }
    return pd.DataFrame(data)


def create_sample_stock_daily_data() -> pd.DataFrame:
    """åˆ›å»ºç¤ºä¾‹è‚¡ç¥¨æ—¥çº¿æ•°æ®"""
    data = {
        'ts_code': ['000001.SZ', '000001.SZ', '000002.SZ'],
        'trade_date': ['20240101', '20240102', '20240101'],
        'open': [10.50, 10.60, 8.20],
        'high': [10.80, 10.90, 8.50],
        'low': [10.40, 10.50, 8.10],
        'close': [10.70, 10.80, 8.30],
        'pre_close': [10.45, 10.70, 8.15],
        'change': [0.25, 0.10, 0.15],
        'pct_chg': [2.39, 0.93, 1.84],
        'vol': [1000000, 800000, 1200000],
        'amount': [10700000, 8640000, 9960000]
    }
    return pd.DataFrame(data)


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®æ“ä½œåŠŸèƒ½"""
    print("ğŸš€ åŸºäºSchemaçš„æ•°æ®æ“ä½œç¤ºä¾‹")
    print("=" * 50)
    
    schema_file = "/Users/yapex/workspace/stock_downloader/stock_schema.toml"
    operator = SchemaDataOperator(schema_file)
    
    try:
        # 1. åˆå§‹åŒ–
        operator.initialize()
        
        # 2. æ’å…¥è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®
        print("\nğŸ“ æ’å…¥è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯æ•°æ®...")
        stock_basic_data = create_sample_stock_basic_data()
        operator.insert_sample_data('stock_basic', stock_basic_data)
        
        # 3. æ’å…¥è‚¡ç¥¨æ—¥çº¿æ•°æ®
        print("\nğŸ“ æ’å…¥è‚¡ç¥¨æ—¥çº¿æ•°æ®...")
        stock_daily_data = create_sample_stock_daily_data()
        operator.insert_sample_data('stock_daily', stock_daily_data)
        
        # 4. æŸ¥è¯¢æ•°æ®
        print("\nğŸ“Š æŸ¥è¯¢è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯...")
        basic_result = operator.query_data('stock_basic')
        print(basic_result.to_string(index=False))
        
        print("\nğŸ“Š æŸ¥è¯¢è‚¡ç¥¨æ—¥çº¿æ•°æ®...")
        daily_result = operator.query_data('stock_daily')
        print(daily_result.to_string(index=False))
        
        # 5. è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“ˆ è¡¨ç»Ÿè®¡ä¿¡æ¯:")
        operator.get_table_stats('stock_basic')
        operator.get_table_stats('stock_daily')
        
        # 6. æ¼”ç¤ºå¤æ‚æŸ¥è¯¢
        print("\nğŸ” æ¼”ç¤ºå¤æ‚æŸ¥è¯¢ - è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ä¸æ—¥çº¿æ•°æ®å…³è”:")
        join_sql = """
        SELECT 
            b.ts_code,
            b.name,
            b.industry,
            d.trade_date,
            d.close,
            d.pct_chg
        FROM stock_basic b
        JOIN stock_daily d ON b.ts_code = d.ts_code
        ORDER BY d.trade_date, b.ts_code
        """
        
        join_result = operator.conn.execute(join_sql).fetchdf()
        print(join_result.to_string(index=False))
        
        # 7. æ¼”ç¤º Upsert åŠŸèƒ½
        print("\nğŸ”„ æ¼”ç¤º Upsert åŠŸèƒ½ - å¢é‡æ›´æ–°è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯:")
        
        # åˆ›å»ºåŒ…å«æ›´æ–°å’Œæ–°å¢æ•°æ®çš„DataFrame
        upsert_data = pd.DataFrame({
            'ts_code': ['000001.SZ', '000003.SZ'],  # 000001.SZæ›´æ–°ï¼Œ000003.SZæ–°å¢
            'symbol': ['000001', '000003'],
            'name': ['å¹³å®‰é“¶è¡Œ(æ›´æ–°)', 'å›½å†œç§‘æŠ€'],  # æ›´æ–°å¹³å®‰é“¶è¡Œåç§°
            'area': ['æ·±åœ³', 'æ·±åœ³'],
            'industry': ['é“¶è¡Œ', 'å†œä¸š'],
            'cnspell': ['PAYH', 'NGKJ'],
            'market': ['ä¸»æ¿', 'ä¸»æ¿'],
            'list_date': ['19910403', '19970515'],
            'act_name': ['å¹³å®‰é“¶è¡Œè‚¡ä»½æœ‰é™å…¬å¸(æ›´æ–°)', 'æ·±åœ³ä¸­å›½å†œå¤§ç§‘æŠ€è‚¡ä»½æœ‰é™å…¬å¸'],
            'act_ent_type': ['è‚¡ä»½æœ‰é™å…¬å¸', 'è‚¡ä»½æœ‰é™å…¬å¸']
        })
        
        operator.upsert_data('stock_basic', upsert_data)
        
        # æŸ¥çœ‹æ›´æ–°åçš„ç»“æœ
        print("\nğŸ“Š Upsert åçš„è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯:")
        updated_result = operator.query_data('stock_basic', limit=10)
        print(updated_result.to_string(index=False))
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯å˜åŒ–
        operator.get_table_stats('stock_basic')
        
    except Exception as e:
        print(f"âŒ æ‰§è¡Œå¤±è´¥: {e}")
        
    finally:
        operator.close()
        print("\nğŸ”š ç¨‹åºç»“æŸ")


if __name__ == "__main__":
    main()